# Monte-Carlo-Simulation zur Resonanzanalyse

## Einleitung

Die Monte-Carlo-Simulation ist ein zentrales Werkzeug in der statistischen Auswertung wissenschaftlicher DatensÃ¤tze. In dieser Analyse dient sie dazu, die Wahrscheinlichkeit zu bestimmen, mit der ein beobachteter Ãœberschuss an Ereignissen im Bereich einer vermuteten Resonanzstelle (**ğ“”**) rein zufÃ¤llig durch den Hintergrund erklÃ¤rt werden kÃ¶nnte.

### Wissenschaftlicher Kontext

Monte-Carlo-Tests sind Standard in der modernen Physik, Data Science und vielen anderen Forschungsfeldern, wenn analytische LÃ¶sungen zu komplex oder nicht verfÃ¼gbar sind. Sie erlauben eine robuste, empirische Bestimmung von Signifikanzen, insbesondere bei adaptiven oder nicht-trivialen Suchverfahren wie in dieser Resonanzanalyse.

## Ziel

Das Ziel ist es, die empirische Signifikanz (p-Wert) der Beobachtungen zu quantifizieren, indem viele Hintergrund-Szenarien simuliert und mit den realen Daten verglichen werden.

## Methodik

### Hintergrundmodellierung

* Die Hintergrundverteilung wird aus den Messdaten extrahiert â€“ unter explizitem Ausschluss der Signalbereiche (um die untersuchten **ğ“”**).
* Ein Kernel-Density-Estimator (KDE) wird verwendet, um daraus eine glatte Wahrscheinlichkeitsverteilung zu erzeugen.

### DurchfÃ¼hrung der Monte-Carlo-Simulation

* Es werden viele (z.B. 1.000â€“10.000) *Pseudo-Experimente* durchgefÃ¼hrt, bei denen jeweils die gleiche Anzahl an Events wie im Originaldatensatz aus dem KDE-Modell gezogen wird.
* FÃ¼r jedes *Pseudo-Experiment* wird die vollstÃ¤ndige Resonanzanalyse wiederholt:
  * Trefferzahlen in variablen Fenstern (**Î”**) um jedes **ğ“”** werden bestimmt.
  * Die p-Werte werden mit den gleichen Tests wie fÃ¼r die Originaldaten berechnet.
  * Die jeweils optimalen FenstergrÃ¶ÃŸen werden automatisch bestimmt.
* Es werden die jeweils extremsten Trefferzahlen und p-Werte dokumentiert.

### Bestimmung des empirischen p-Werts

* Der empirische p-Wert ist der Anteil der SimulationsdurchlÃ¤ufe, in denen ein ebenso extremer oder extremerer Ãœberschuss wie in den realen Daten gefunden wurde.
* Beispiel: Ist der empirische p-Wert â‰ˆ 0, wurde in keiner Simulation ein so starkes Signal wie in den echten Daten beobachtet.

## Visualisierung der Ergebnisse

### 1. Monte-Carlo-Hits vs. echte Treffer

Das Histogramm zeigt, wie hÃ¤ufig in der Monte-Carlo-Simulation bestimmte Trefferzahlen im optimalen Fenster fÃ¼r jedes **ğ“”** vorkommen. Die rote Linie markiert den Wert aus den echten Daten.

![Histogramm MC vs Echt](report_out/figures/hist_mc_vs_real_hits.png)

---

### 2. p-Wert-VerlÃ¤ufe Ã¼ber die Fensterbreite **Î”**

Hier siehst du fÃ¼r jede Resonanzstelle **ğ“”** die p-Werte aus den MC-Simulationen (Median und 68%-Intervall) und den realen Daten in AbhÃ¤ngigkeit von **Î”**.

![p-Wert-VerlÃ¤ufe](report_out/figures/pvalue_curves.png)

---

### 3. Heatmaps: Trefferanzahl Ã¼ber **ğ“”** und **Î”**

Die Heatmaps zeigen die Trefferzahlen fÃ¼r alle Kombinationen aus **ğ“”** und **Î”**, einmal fÃ¼r die realen Daten und einmal als Mittelwert der Monte-Carlo-Simulationen.

![Heatmaps Trefferanzahl](report_out/figures/heatmaps_hits.png)

---

## Interpretation

* Die Monte-Carlo-Simulation zeigt, wie auÃŸergewÃ¶hnlich die beobachteten ÃœberschÃ¼sse im Vergleich zum Hintergrund sind.
* Empirische p-Werte < 0,01 â€“ insbesondere p â‰ˆ 0 â€“ sprechen fÃ¼r eine extrem geringe Wahrscheinlichkeit, dass die Befunde durch Zufall entstehen.
* Die grafische GegenÃ¼berstellung (Histogramme, p-Wert-Kurven, Heatmaps) macht die Differenz zwischen Signal und Hintergrund anschaulich.

## Hinweise zum Code

* Die Simulation nutzt `scikit-learn` fÃ¼r KDE, `numpy` und `pandas` fÃ¼r Datenhandling und `matplotlib` fÃ¼r die Visualisierung.
* Fortschrittsbalken (`tqdm`) zeigen den Simulationsfortschritt an.
* Alle wichtigen Parameter wie **ğ“”**, **Î”** und die Anzahl der Simulationen sind zentral in `config.py` eingestellt.
* Die wichtigsten Plots werden automatisch im Ordner `report_out/figures` abgelegt und sind hier direkt eingebunden.

### AusfÃ¼hrung der Simulation

Um die Monte-Carlo-Simulation selbst auszufÃ¼hren, folge diesen Schritten:

1. Navigiere in das Verzeichnis des Projekts.
2. Stelle sicher, dass alle erforderlichen Python-Pakete installiert sind (siehe ggf. `requirements.txt`).
3. Starte das Hauptskript, z.B. mit:

   ```bash
   python fakten/empirisch/monte_carlo_test/run.py
   ```

   oder fÃ¼hre das begleitende Jupyter Notebook aus, falls vorhanden.

4. Die erzeugten Ergebnisse und Plots findest du im Ordner `report_out/figures`.

## Fazit

Die Monte-Carlo-Methode bietet eine robuste MÃ¶glichkeit zur statistischen Validierung von Resonanzeffekten. Durch die gezielte Modellierung des Hintergrunds und die wiederholte Zufallssimulation kann die Signifikanz von Beobachtungen empirisch und nachvollziehbar bestimmt werden.

ZukÃ¼nftige Erweiterungen kÃ¶nnten adaptive FenstergrÃ¶ÃŸen, multiple Hypothesentests oder bayesianische AnsÃ¤tze integrieren.

---

Â© Dominic-RenÃ© Schu â€“ Resonanzfeldtheorie 2025

---

[ZurÃ¼ck zur Ãœbersicht](../../../README.md)